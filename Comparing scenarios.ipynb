{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States, actions and parameters of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1,2,3,4,5,6,7,8,9]\n",
    "actions = ['droite', 'haut','gauche','bas']\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1 #learning rate\n",
    "gamma = 0.6 #discount factor\n",
    "epsilon = 0.1 #probability of making a greedy action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework deterministic scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(u):\n",
    "    if u == 'gauche':\n",
    "        mini = np.array([[1,0,0],[1,0,0],[0,1,0]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "    \n",
    "    if u == 'droite':\n",
    "        mini = np.array([[0,1,0],[0,0,1],[0,0,1]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "        \n",
    "    if u == 'haut':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [mini, zeros_block, zeros_block],[zeros_block,mini,zeros_block]])\n",
    "        \n",
    "    if u == 'bas':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[zeros_block, mini, zeros_block], [zeros_block, zeros_block, mini],[zeros_block,zeros_block, mini]])    \n",
    "    return tr\n",
    "\n",
    "def transition(s, u):\n",
    "    tr = transition_matrix(u)\n",
    "    ligne = tr[s - 1]\n",
    "    return np.random.choice(states, size=1, replace=True, p=ligne)[0]\n",
    "\n",
    "def reward(s, u):\n",
    "    if s==3:\n",
    "        return 10\n",
    "    elif s==4:\n",
    "        return -10\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def  env_step(s, u):\n",
    "    next_state = transition(s,u)\n",
    "    rew = reward(s, u)\n",
    "    done = ((s == 3) or (next_state == 3))\n",
    "    return next_state, rew, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework windy scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'gauche'#provenance du vent\n",
    "f = 0.1 #force du vent\n",
    "\n",
    "def transition_matrix_wind(u, wind, force):\n",
    "        \n",
    "    if u == 'gauche':\n",
    "        mini = np.array([[1,0,0],[1,0,0],[0,1,0]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "    if u == 'droite':\n",
    "        mini = np.array([[0,1,0],[0,0,1],[0,0,1]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "    if u == 'haut':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [mini, zeros_block, zeros_block],[zeros_block,mini,zeros_block]])\n",
    "    if u == 'bas':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[zeros_block, mini, zeros_block], [zeros_block, zeros_block, mini],[zeros_block,zeros_block, mini]])\n",
    "    \n",
    "    #adding a wind component:\n",
    "    if wind == 'droite':\n",
    "        mini_wind = np.array([[1-force,force,0],[0,1-force,force],[0,0,1]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        wind_mat = np.block([[mini_wind, zeros_block, zeros_block], [zeros_block,mini_wind, zeros_block],[zeros_block,zeros_block,mini_wind]])\n",
    "    if wind == 'gauche':\n",
    "        mini_wind = np.array([[1,0,0],[force,1-force,0],[0,force,1-force]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        wind_mat = np.block([[mini_wind, zeros_block, zeros_block], [zeros_block,mini_wind, zeros_block],[zeros_block,zeros_block,mini_wind]])\n",
    "    if wind == 'haut':\n",
    "        mini_wind1 = np.identity(3)*force\n",
    "        mini_wind2 = np.identity(3)*(1-force)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        wind_mat = np.block([[np.identity(3), zeros_block, zeros_block], [mini_wind1,mini_wind2, zeros_block],[zeros_block,mini_wind1,mini_wind2]])\n",
    "    if wind == 'bas':\n",
    "        mini_wind1 = np.identity(3)*force\n",
    "        mini_wind2 = np.identity(3)*(1-force)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        wind_mat = np.block([[mini_wind2,mini_wind1, zeros_block],[zeros_block,mini_wind2,mini_wind1], [zeros_block, zeros_block,np.identity(3)]])\n",
    "        \n",
    "    return (np.dot(tr, wind_mat))\n",
    "\n",
    "def transition_wind(s, u, wind, force):\n",
    "    tr = transition_matrix_wind(u, wind, force)\n",
    "    ligne = tr[s - 1]\n",
    "    return np.random.choice(states, size=1, replace=True, p=ligne)[0]\n",
    "\n",
    "def reward(s, u):\n",
    "    if s==3:\n",
    "        return 10\n",
    "    elif s==4:\n",
    "        return -10\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def env_step_wind(s, u, wind, force):\n",
    "    next_state = transition_wind(s, u, wind, force)\n",
    "    rew = reward(s, u)\n",
    "    done = ((s == 3) or (next_state == 3))\n",
    "    return next_state, rew, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework very windy (random) scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.random.rand(len(states),len(states))\n",
    "matrix2 = np.random.rand(len(states),len(states))\n",
    "matrix3 = np.random.rand(len(states),len(states))\n",
    "matrix4 = np.random.rand(len(states),len(states))\n",
    "\n",
    "matrix1 = matrix1/matrix1.sum(axis=1)[:,None]\n",
    "matrix2 = matrix2/matrix2.sum(axis=1)[:,None]\n",
    "matrix3 = matrix3/matrix3.sum(axis=1)[:,None]\n",
    "matrix4 = matrix4/matrix4.sum(axis=1)[:,None]\n",
    "\n",
    "def transition_matrix_random(u, m1, m2,m3,m4):\n",
    "    if u == 'gauche':\n",
    "        tr = m1\n",
    "    if u == 'droite':\n",
    "        tr = m2\n",
    "    if u == 'haut':\n",
    "        tr = m3\n",
    "    if u == 'bas':\n",
    "        tr = m4\n",
    "    return(tr)\n",
    "\n",
    "def transition_random(s, u, m1, m2,m3,m4):\n",
    "    tr = transition_matrix_random(u, m1, m2,m3,m4)\n",
    "    ligne = tr[s - 1]\n",
    "    return np.random.choice(states, size=1, replace=True, p=ligne)[0]\n",
    "\n",
    "def reward(s, u):\n",
    "    if s==3:\n",
    "        return 10\n",
    "    elif s==4:\n",
    "        return -10\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def env_step_random(s, u, m1, m2,m3,m4):\n",
    "    next_state = transition_random(s, u, m1, m2,m3,m4)\n",
    "    rew = reward(s, u)\n",
    "    done = ((s == 3) or (next_state == 3))\n",
    "    return next_state, rew, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing optimal values using value iteration algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the convergence of the Q-learning algorithm, we first computed the $Q^*$ values using the value iteration algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Q^*$ deterministic scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['droite', 'haut', 'gauche', 'bas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.   ,   5.4  ,   5.4  ,  -2.76 ],\n",
       "       [ 15.   ,   9.   ,   5.4  ,   5.4  ],\n",
       "       [ 25.   ,  25.   ,  19.   ,  19.   ],\n",
       "       [ -4.6  ,  -4.6  , -12.76 ,  -8.056],\n",
       "       [  9.   ,   9.   ,  -2.76 ,   3.24 ],\n",
       "       [  9.   ,  15.   ,   5.4  ,   5.4  ],\n",
       "       [  3.24 ,  -2.76 ,   1.944,   1.944],\n",
       "       [  5.4  ,   5.4  ,   1.944,   3.24 ],\n",
       "       [  5.4  ,   9.   ,   3.24 ,   5.4  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dp = np.zeros([len(states),len(actions)])\n",
    "q_dp[2]=10\n",
    "q_dp[3]=-10\n",
    "\n",
    "\n",
    "for t in range(100, 0,-1):\n",
    "    q_dp_new = q_dp.copy()\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(actions)):\n",
    "            u = actions[j]\n",
    "            s = states[i]\n",
    "            trmat = transition_matrix(u)\n",
    "            ligne_i = trmat[i]\n",
    "            q_max = np.max(q_dp, axis = 1)\n",
    "            q_dp_new[i][j] = reward(s,u) + gamma*np.dot(q_max, ligne_i)\n",
    "    q_dp = q_dp_new\n",
    "\n",
    "print(actions)\n",
    "q_dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Q^*$ windy scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['droite', 'haut', 'gauche', 'bas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  7.75531915,   4.65319149,   4.65319149,  -3.20808511],\n",
       "       [ 13.5       ,   7.75531915,   4.65319149,   3.86706383],\n",
       "       [ 23.5       ,  23.5       ,  17.75531915,  17.75531915],\n",
       "       [ -6.13293617,  -5.34680851, -13.20808511,  -8.46438361],\n",
       "       [  7.75531915,   7.75531915,  -3.20808511,   2.55936064],\n",
       "       [  7.75531915,  13.5       ,   3.86706383,   4.45518334],\n",
       "       [  2.55936064,  -3.20808511,   1.53561639,   1.53561639],\n",
       "       [  4.45518334,   3.86706383,   1.53561639,   2.55936064],\n",
       "       [  4.45518334,   7.75531915,   2.55936064,   4.45518334]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dp_wind = np.zeros([len(states),len(actions)])\n",
    "q_dp_wind[2]=10\n",
    "q_dp_wind[3]=-10\n",
    "\n",
    "\n",
    "for t in range(100, 0,-1):\n",
    "    q_dp_wind_new = q_dp_wind.copy()\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(actions)):\n",
    "            u = actions[j]\n",
    "            s = states[i]\n",
    "            trmat = transition_matrix_wind(u,w,f)\n",
    "            ligne_i = trmat[i]\n",
    "            q_max = np.max(q_dp_wind, axis = 1)\n",
    "            q_dp_wind_new[i][j] = reward(s,u) + gamma*np.dot(q_max, ligne_i)\n",
    "    q_dp_wind = q_dp_wind_new\n",
    "\n",
    "print(actions)\n",
    "q_dp_wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Q^*$ very windy (random) scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['droite', 'haut', 'gauche', 'bas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.96176279,  1.45979628, -0.13825644,  0.72389366],\n",
       "       [ 1.08623482,  2.17775518,  1.33878004,  1.90948802],\n",
       "       [10.77308385, 11.55296575, 10.36073613, 11.96120928],\n",
       "       [-8.71530887, -8.09182283, -9.67268573, -8.44338934],\n",
       "       [ 1.52558309,  0.07020289,  1.81077755,  0.94100724],\n",
       "       [ 2.22932152,  0.38954168,  0.8951855 ,  0.08328424],\n",
       "       [ 0.57393198,  1.13642931,  0.83745809,  1.15559096],\n",
       "       [ 0.33073403,  1.11204188,  1.12615895,  1.30708253],\n",
       "       [ 0.98155357,  0.93091537,  1.10330044,  0.02865551]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dp_random = np.zeros([len(states),len(actions)])\n",
    "q_dp_random[2]=10\n",
    "q_dp_random[3]=-10\n",
    "\n",
    "\n",
    "for t in range(100, 0,-1):\n",
    "    q_dp_random_new = q_dp_random.copy()\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(actions)):\n",
    "            u = actions[j]\n",
    "            s = states[i]\n",
    "            trmat = transition_matrix_random(u, matrix1, matrix2, matrix3, matrix4)\n",
    "            ligne_i = trmat[i]\n",
    "            q_max = np.max(q_dp_random, axis = 1)\n",
    "            q_dp_random_new[i][j] = reward(s,u) + gamma*np.dot(q_max, ligne_i)\n",
    "    q_dp_random = q_dp_random_new\n",
    "\n",
    "print(actions)\n",
    "q_dp_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of Q-learning : comparing number of iterations and error, executing time and error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the Q-learning algorithm, and applied it tothe different scenarios.  The goal of our experiment is to challenge the paper over thelimitations we identified in the previous section.  Our aim is to test the convergence of the algorithm, considering the real $Q^∗$values computed using a value iteration algorithm. We measure the error as the mean square error between the real $Q^∗$ values and the computed $Q$ values: $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in deterministic scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_steps = np.logspace(1, 6, 15, endpoint=False).astype(int)\n",
    "error = np.zeros(len(time_steps))\n",
    "q_table = np.zeros([len(states),len(actions)])\n",
    "error[0] = (np.mean((q_table-q_dp)**2))**0.5\n",
    "\n",
    "for k in range(len(time_steps)-1):\n",
    "    print(k)\n",
    "    time = time_steps[k]\n",
    "    time_next = time_steps[k+1]\n",
    "    \n",
    "    for i in range(time, time_next):\n",
    "        s = np.random.randint(1,len(states)+1) #initial state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs, penalties, rew = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        for j in range(3):\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "            else:\n",
    "                action_index = np.argmax(q_table[state_index]) # Exploit learned values\n",
    "\n",
    "            u = actions[action_index]\n",
    "\n",
    "            next_state, rew, done = env_step(s, u)\n",
    "            next_state_index = next_state - 1\n",
    "\n",
    "            old_value = q_table[state_index, action_index]\n",
    "            next_max = np.max(q_table[next_state_index])\n",
    "\n",
    "            new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "            q_table[state_index, action_index] = new_value\n",
    "\n",
    "            if rew == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            s = next_state\n",
    "            state_index = s-1\n",
    "\n",
    "    error[k+1] = (np.mean((q_table-q_dp)**2))**0.5\n",
    "\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in windy scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_steps_wind = np.logspace(1, 6, 15, endpoint=False).astype(int)\n",
    "error_wind = np.zeros(len(time_steps))\n",
    "q_table_wind = np.zeros([len(states),len(actions)])\n",
    "error_wind[0] = (np.mean((q_table_wind-q_dp_wind)**2))**0.5\n",
    "\n",
    "for k in range(len(time_steps_wind)-1):\n",
    "    print(k)\n",
    "    time = time_steps_wind[k]\n",
    "    time_next = time_steps_wind[k+1]\n",
    "    \n",
    "    for i in range(time, time_next):\n",
    "        s = np.random.randint(1,len(states)+1) #initial state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs, penalties, rew = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        for j in range(3):\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "            else:\n",
    "                action_index = np.argmax(q_table_wind[state_index]) # Exploit learned values\n",
    "\n",
    "            u = actions[action_index]\n",
    "\n",
    "            next_state, rew, done = env_step_wind(s, u, w, f)\n",
    "            next_state_index = next_state - 1\n",
    "\n",
    "            old_value = q_table_wind[state_index, action_index]\n",
    "            next_max = np.max(q_table_wind[next_state_index])\n",
    "\n",
    "            new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "            q_table_wind[state_index, action_index] = new_value\n",
    "\n",
    "            if rew == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            s = next_state\n",
    "            state_index = s-1\n",
    "\n",
    "            \n",
    "    error_wind[k+1] = (np.mean((q_table_wind-q_dp_wind)**2))**0.5\n",
    "\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in very windy (random) scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_steps_random = np.logspace(1, 6, 15, endpoint=False).astype(int)\n",
    "error_random = np.zeros(len(time_steps))\n",
    "q_table_random = np.zeros([len(states),len(actions)])\n",
    "error_random[0] = (np.mean((q_table_random-q_dp_random)**2))**0.5\n",
    "\n",
    "for k in range(len(time_steps_random)-1):\n",
    "    print(k)\n",
    "    time = time_steps_random[k]\n",
    "    time_next = time_steps_random[k+1]\n",
    "\n",
    "    for i in range(time, time_next):\n",
    "        s = np.random.randint(1,len(states)+1) #initial state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs, penalties, rew = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        for j in range(3):\n",
    "            if np.random.uniform(0, 1) < epsilon:\n",
    "                action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "            else:\n",
    "                action_index = np.argmax(q_table_random[state_index]) # Exploit learned values\n",
    "\n",
    "            u = actions[action_index]\n",
    "\n",
    "            next_state, rew, done = env_step_random(s, u, matrix1, matrix2, matrix3, matrix4)\n",
    "            next_state_index = next_state - 1\n",
    "\n",
    "            old_value = q_table_random[state_index, action_index]\n",
    "            next_max = np.max(q_table_random[next_state_index])\n",
    "\n",
    "            new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "            q_table_random[state_index, action_index] = new_value\n",
    "\n",
    "            if rew == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            s = next_state\n",
    "            state_index = s-1\n",
    "\n",
    "            \n",
    "    error_random[k+1] = (np.mean((q_table_random-q_dp_random)**2))**0.5\n",
    "\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_plot, = plt.plot(np.log(time_steps),error )\n",
    "error_plot_wind, = plt.plot(np.log(time_steps_wind),error_wind)\n",
    "error_plot_random, = plt.plot(np.log(time_steps_random), error_random)\n",
    "\n",
    "plt.legend([error_plot, error_plot_wind,error_plot_random ], ['Deterministic', 'Windy', 'Random'])\n",
    "plt.xlabel('log - number of iterations')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenging the algorithm: stopping before convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There  are  actually  plenty  of  situations  where  conducting  experimentsis expensive, and the users might need to interrupt the process or limit the number ofiterations, while still having a good estimation and a good policy.  What would happenwith Q-learning if someone needed to stop it before convergence ?  Could one still relyon the results ?  How bad would it be ?\n",
    "Let's take one example: we are only able to conduct 500 iterations of the Q-learning algorithm.\n",
    "We will compare the estimation of the $Q$ values and the policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nit = 500 #number of iterations of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic scenario : 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_table500 = np.zeros([len(states),len(actions)])\n",
    "\n",
    "for i in range(Nit):\n",
    "    s = np.random.randint(1,len(states)+1) #initial state\n",
    "    state_index = s-1\n",
    "\n",
    "    epochs, penalties, rew = 0, 0, 0\n",
    "    done = False\n",
    "\n",
    "    for j in range(3):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "        else:\n",
    "            action_index = np.argmax(q_table500[state_index]) # Exploit learned values\n",
    "\n",
    "        u = actions[action_index]\n",
    "\n",
    "        next_state, rew, done = env_step(s, u)\n",
    "        next_state_index = next_state - 1\n",
    "\n",
    "        old_value = q_table500[state_index, action_index]\n",
    "        next_max = np.max(q_table500[next_state_index])\n",
    "\n",
    "        new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "        q_table500[state_index, action_index] = new_value\n",
    "\n",
    "        if rew == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        s = next_state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windy scenario : 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_table_wind500 = np.zeros([len(states),len(actions)])\n",
    "\n",
    "for i in range(500):\n",
    "    s = np.random.randint(1,len(states)+1) #initial state\n",
    "    state_index = s-1\n",
    "    \n",
    "    epochs, penalties, rew = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    for j in range(5):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "        else:\n",
    "            action_index = np.argmax(q_table_wind500[state_index]) # Exploit learned values\n",
    "\n",
    "        u = actions[action_index]\n",
    "\n",
    "        next_state, rew, done = env_step_wind(s, u, w, f)\n",
    "        next_state_index = next_state - 1\n",
    "        \n",
    "        old_value = q_table_wind500[state_index, action_index]\n",
    "        next_max = np.max(q_table_wind500[next_state_index])\n",
    "\n",
    "        new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "        q_table_wind500[state_index, action_index] = new_value\n",
    "\n",
    "        if rew == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        s = next_state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very windy (random) scenario:500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_table_random500 = np.zeros([len(states),len(actions)])\n",
    "\n",
    "for i in range(500):\n",
    "    s = np.random.randint(1,len(states)+1) #initial state\n",
    "    state_index = s-1\n",
    "    \n",
    "    epochs, penalties, rew = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    for j in range(5):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "        else:\n",
    "            action_index = np.argmax(q_table_random500[state_index]) # Exploit learned values\n",
    "\n",
    "        u = actions[action_index]\n",
    "\n",
    "        next_state, rew, done = env_step_random(s, u, matrix1, matrix2, matrix3, matrix4)\n",
    "        next_state_index = next_state - 1\n",
    "        \n",
    "        old_value = q_table_random500[state_index, action_index]\n",
    "        next_max = np.max(q_table_random500[next_state_index])\n",
    "\n",
    "        new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "        q_table_random500[state_index, action_index] = new_value\n",
    "\n",
    "        if rew == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        s = next_state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error and policy differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "error500 = (np.mean((q_table500-q_dp)**2))**0.5\n",
    "error_wind500 = (np.mean((q_table_wind500-q_dp_wind)**2))**0.5\n",
    "error_random500 = (np.mean((q_table_random500-q_dp_random)**2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9657881001019586\n",
      "2.7591287191473417\n",
      "1.8593277983323746\n"
     ]
    }
   ],
   "source": [
    "print(error500)\n",
    "print(error_wind500)\n",
    "print(error_random500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(q):\n",
    "    return([actions[i] for i in np.argmax(q, axis = 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haut',\n",
       " 'gauche',\n",
       " 'droite',\n",
       " 'haut',\n",
       " 'bas',\n",
       " 'droite',\n",
       " 'gauche',\n",
       " 'haut',\n",
       " 'droite']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_policy(q_table_random500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
