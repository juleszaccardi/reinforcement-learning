{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1,2,3,4,5,6,7,8,9]\n",
    "actions = ['droite', 'haut','gauche','bas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(u):\n",
    "    if u == 'gauche':\n",
    "        mini = np.array([[1,0,0],[1,0,0],[0,1,0]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "    \n",
    "    if u == 'droite':\n",
    "        mini = np.array([[0,1,0],[0,0,1],[0,0,1]])\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [zeros_block,mini, zeros_block],[zeros_block,zeros_block,mini]])\n",
    "        \n",
    "    if u == 'haut':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[mini, zeros_block, zeros_block], [mini, zeros_block, zeros_block],[zeros_block,mini,zeros_block]])\n",
    "        \n",
    "    if u == 'bas':\n",
    "        mini = np.eye(3)\n",
    "        zeros_block = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "        tr = np.block([[zeros_block, mini, zeros_block], [zeros_block, zeros_block, mini],[zeros_block,zeros_block, mini]])    \n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(s, u):\n",
    "    tr = transition_matrix(u)\n",
    "    ligne = tr[s - 1]\n",
    "    return np.random.choice(states, size=1, replace=True, p=ligne)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s, u):\n",
    "#     if ((s == 2) and (u=='droite')) or (s==3) or ((s==6) and (u=='haut')):\n",
    "#         return(10)\n",
    "#     elif ((s==4)) or ((s==1) and (u=='bas')) or ((s==5) and (u=='gauche')) or ((s==7) and (u == 'haut')):\n",
    "#         return(-10)\n",
    "    if s==3:\n",
    "        return 10\n",
    "    elif s==4:\n",
    "        return -10\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  env_step(s, u):\n",
    "    next_state = transition(s,u)\n",
    "    rew = reward(s, u)\n",
    "    done = ((s == 3) or (next_state == 3))\n",
    "    return next_state, rew, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([len(states),len(actions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    s = np.random.randint(1,len(states)+1) #initial state\n",
    "    state_index = s-1\n",
    "    \n",
    "    epochs, penalties, rew = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    for j in range(3):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action_index = np.random.randint(0,len(actions)) # Explore action space\n",
    "        else:\n",
    "            action_index = np.argmax(q_table[state_index]) # Exploit learned values\n",
    "\n",
    "        u = actions[action_index]\n",
    "\n",
    "        next_state, rew, done = env_step(s, u)\n",
    "        next_state_index = next_state - 1\n",
    "        \n",
    "        old_value = q_table[state_index, action_index]\n",
    "        next_max = np.max(q_table[next_state_index])\n",
    "\n",
    "        new_value = (1 - alpha) * old_value + alpha * (rew + gamma * next_max)\n",
    "        q_table[state_index, action_index] = new_value\n",
    "\n",
    "        if rew == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        s = next_state\n",
    "        state_index = s-1\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['droite', 'haut', 'gauche', 'bas']\n",
      "[[  9.           5.39126415   5.39530811  -2.74919147]\n",
      " [ 15.           8.99944262   5.39483282   5.39605199]\n",
      " [ 25.          25.          19.          19.        ]\n",
      " [ -4.61347     -4.6        -12.50596377  -7.7408071 ]\n",
      " [  9.           8.68931742  -2.60033457   3.18391972]\n",
      " [  8.9999709   15.           5.39994817   5.39999697]\n",
      " [  3.24        -2.6434041    1.8703958    1.8772461 ]\n",
      " [  5.4          5.39213509   1.92701706   3.23352088]\n",
      " [  5.39958833   9.           3.23769652   5.3998709 ]]\n"
     ]
    }
   ],
   "source": [
    "print(actions)\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing values using dynamic programming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dp = np.zeros([len(states),len(actions)])\n",
    "q_dp[2]=10\n",
    "q_dp[3]=-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(100, 0,-1):\n",
    "    q_dp_new = q_dp.copy()\n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(actions)):\n",
    "            u = actions[j]\n",
    "            s = states[i]\n",
    "            trmat = transition_matrix(u)\n",
    "            ligne_i = trmat[i]\n",
    "            q_max = np.max(q_dp, axis = 1)\n",
    "            q_dp_new[i][j] = reward(s,u) + gamma*np.dot(q_max, ligne_i)\n",
    "    q_dp = q_dp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['droite', 'haut', 'gauche', 'bas']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.   ,   5.4  ,   5.4  ,  -2.76 ],\n",
       "       [ 15.   ,   9.   ,   5.4  ,   5.4  ],\n",
       "       [ 25.   ,  25.   ,  19.   ,  19.   ],\n",
       "       [ -4.6  ,  -4.6  , -12.76 ,  -8.056],\n",
       "       [  9.   ,   9.   ,  -2.76 ,   3.24 ],\n",
       "       [  9.   ,  15.   ,   5.4  ,   5.4  ],\n",
       "       [  3.24 ,  -2.76 ,   1.944,   1.944],\n",
       "       [  5.4  ,   5.4  ,   1.944,   3.24 ],\n",
       "       [  5.4  ,   9.   ,   3.24 ,   5.4  ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(actions)\n",
    "q_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.        ,   5.39126415,   5.39530811,  -2.74919147],\n",
       "       [ 15.        ,   8.99944262,   5.39483282,   5.39605199],\n",
       "       [ 25.        ,  25.        ,  19.        ,  19.        ],\n",
       "       [ -4.61347   ,  -4.6       , -12.50596377,  -7.7408071 ],\n",
       "       [  9.        ,   8.68931742,  -2.60033457,   3.18391972],\n",
       "       [  8.9999709 ,  15.        ,   5.39994817,   5.39999697],\n",
       "       [  3.24      ,  -2.6434041 ,   1.8703958 ,   1.8772461 ],\n",
       "       [  5.4       ,   5.39213509,   1.92701706,   3.23352088],\n",
       "       [  5.39958833,   9.        ,   3.23769652,   5.3998709 ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
